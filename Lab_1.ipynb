{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d792bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representative Document:\n",
      "learn machin use data predict tool make autom appli healthcar financ market detect field artifici intellig focus algorithm imit way human power identifi pattern process wide rang area transport patient outcom diseas person treatment plan fraud trade invest decis also target advertis segment custom sale trend rise big becom essenti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ameyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ameyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure the necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "# Function to generate representative document\n",
    "def generate_representative_doc(text):\n",
    "    # Preprocess the text\n",
    "    tokens = preprocess_text(text)\n",
    "    \n",
    "    # Get the frequency of each token\n",
    "    freq_dist = Counter(tokens)\n",
    "    \n",
    "    # Sort by frequency and select the most frequent terms\n",
    "    sorted_terms = sorted(freq_dist.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Create a representative document from the top terms\n",
    "    representative_doc = ' '.join([term for term, freq in sorted_terms[:50]])  # Adjust the number of terms as needed\n",
    "    \n",
    "    return representative_doc\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Read the text file\n",
    "    with open('Lab_1.txt', 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Generate the representative document\n",
    "    representative_doc = generate_representative_doc(text)\n",
    "    \n",
    "    # Output the result\n",
    "    print(\"Representative Document:\")\n",
    "    print(representative_doc)\n",
    "    \n",
    "    # Optionally, save the output to a file\n",
    "    with open('output_representative_doc.txt', 'w') as output_file:\n",
    "        output_file.write(representative_doc)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e95899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
